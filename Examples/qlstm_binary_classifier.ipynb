{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e516edaf-e976-4b7f-8635-6642353d8fa3",
   "metadata": {},
   "source": [
    "## Quantum LSTM for classification tasks\n",
    "\n",
    "#### Let us start by training a Quantum Long Short-Term Memory model for the binary classification of IMDB movie reviews.\n",
    "\n",
    "#### We will work with a preprocessed dataset, in which every movie review have been shorten to its most relevant 5 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17b4b40f-a879-4259-83e1-ca034a799bc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/4nwfzz4d2tb_w79xcl4k8gxxn0kqjv/T/ipykernel_47205/3623456619.py:7: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  cmap = get_cmap('tab20c')\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append('../src')\n",
    "import torch\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap('tab20c')\n",
    "colors = cmap.colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d330f235-1685-4fa2-be4f-835456b6680d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = '../Datasets/imdb_top5_vocab20.txt'\n",
    "data = '../../../../Downloads/tcga_top5.txt'\n",
    "\n",
    "with open(data, 'r') as file: reviews = file.readlines()\n",
    "\n",
    "classes = list(set(list(int(review[:2]) for review in reviews)))\n",
    "class_dist = {c: 0 for c in classes}\n",
    "for review in reviews: class_dist[int(review[:2])] += 1\n",
    "train_classes = [0,1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45db77-cbae-4bf4-9a31-ab6b83cb149a",
   "metadata": {},
   "source": [
    "#### The first character of each datapoint is a label. Good reviews are assigned label $1$, while bad ones are assigned label $0$.\n",
    "#### For this tutorial, we will generate a balanced training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c11a2e48-8a90-4893-a6b2-3a69c9173af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlstm_aux import subset_idxs_dist\n",
    "\n",
    "train_size = 60\n",
    "balanced = True\n",
    "randomized = False\n",
    "\n",
    "train_idxs, train_dist = subset_idxs_dist(reviews, train_classes, train_size, balanced, randomized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca38d7d0-2a85-4953-b9c2-3bb72ed5ef37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 10, 15, 18, 19, 20, 23, 25, 27, 33, 36, 41, 43, 44, 45, 47, 48, 49, 51, 54, 55, 56, 62, 65, 73, 74, 80, 89, 93, 94, 99, 100, 105, 106, 108, 110, 111, 114, 117, 122, 123, 124, 129, 132, 133, 139, 162, 165, 168, 175, 178, 186, 191, 196, 203, 218, 224, 234, 249]\n",
      "{0: 20, 1: 20, 2: 20}\n"
     ]
    }
   ],
   "source": [
    "print(train_idxs)\n",
    "print(train_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d38255e2-461e-416b-b97b-df58d945a53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qlstm_aux import words_to_idxs\n",
    "words_to_idxs = words_to_idxs(reviews, train_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be3a2842-fb62-4eab-aacd-2b3007dc03c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n",
      "{'examination': 0, 'performed': 1, 'invasive': 2, 'cell': 3, 'area': 4, 'stage': 5, 'total': 6, 'positive': 7, 'involved': 8, 'site': 9, 'uuid': 10, 'description': 11, 'patient': 12, 'case': 13, 'pathology': 14, 'vascular': 15, 'date': 16, 'posterior': 17, 'additional': 18, 'entirely': 19, 'negative': 20, 'grossly': 21, 'attached': 22, 'measures': 23, 'representative': 24, 'metastatic': 25, 'excision': 26, 'parenchyma': 27, 'metastasis': 28, 'frozen': 29, 'shows': 30, 'adipose': 31, 'pathologic': 32, 'red': 33, 'unremarkable': 34, 'consists': 35, 'iii': 36, 'small': 37, 'diameter': 38, 'free': 39, 'pr': 40, 'biopsy': 41, 'white': 42, 'page': 43, 'number': 44, 'ii': 45, 'extension': 46, 'uninvolved': 47, 'end': 48, 'labeled': 49, 'portion': 50, 'tan': 51, 'measuring': 52, 'adenocarcinoma': 53, 'mass': 54, 'mm': 55, 'areas': 56, 'surgical': 57, 'resection': 58, 'inked': 59, 'blue': 60, 'cells': 61, 'yellow': 62, 'pink': 63, 'anterior': 64, 'microscopic': 65, 'soft': 66, 'present': 67, 'final': 68, 'black': 69, 'greatest': 70, 'dimension': 71, 'surface': 72, 'formalin': 73, 'bisected': 74, 'sectioned': 75, 'margins': 76, 'examined': 77, 'section': 78, 'size': 79, 'gross': 80, 'differentiated': 81}\n"
     ]
    }
   ],
   "source": [
    "print(len(words_to_idxs))\n",
    "print(words_to_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759eb229-61d9-4917-aecb-a98363db642e",
   "metadata": {},
   "source": [
    "#### Next, we define the model we want to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4294e02-9227-49a4-8b18-4f646cb5e49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 8\n",
    "hidden_dim = 6\n",
    "num_words = len(words_to_idxs)\n",
    "num_labels = len(train_classes)\n",
    "num_qubits = 3\n",
    "num_qlayers = 1\n",
    "backend = 'default.qubit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc644214-71b4-40ec-8958-881f1dfcee17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': (1, 4)}\n"
     ]
    }
   ],
   "source": [
    "from qlstm_models import QLSTMClassifier\n",
    "\n",
    "model = QLSTMClassifier(embedding_dim,\n",
    "                        hidden_dim,\n",
    "                        vocab_size=num_words,\n",
    "                        tagset_size=num_labels,\n",
    "                        n_qubits=num_qubits,\n",
    "                        n_qlayers=num_qlayers,\n",
    "                        ising=True,\n",
    "                        probs=False,\n",
    "                        backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abf3cce7-b3b5-4e72-9e2c-937ee19592fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "weights = torch.tensor(list(pow(train_size/len(train_classes)/train_dist[key],3) for key in train_dist.keys()), dtype=torch.float)\n",
    "learning_rate = 0.001\n",
    "\n",
    "loss_function = nn.NLLLoss(weight=weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b564dd26-f5cc-4506-b8c7-2ad3f578064f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "training = {'loss': [], 'acc': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a85dd14-7a84-46db-b7b3-00a7f2cfeead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: -0.3355\tAccuracy: 0.5555999875068665\n",
      "Loss: -0.3822\tAccuracy: 0.6888999938964844\n",
      "Loss: -0.5418\tAccuracy: 0.8222000002861023\n",
      "Loss: -0.6943\tAccuracy: 0.8555999994277954\n",
      "Loss: -0.7974\tAccuracy: 0.9333000183105469\n"
     ]
    }
   ],
   "source": [
    "from numpy import mean, around\n",
    "from numpy.random import shuffle\n",
    "from qlstm_aux import prepare_sequence\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    shuffle(train_idxs)\n",
    "\n",
    "    rank_losses = []\n",
    "    rank_preds = []\n",
    "    rank_targets = []\n",
    "    accuracy = torch.tensor([0], dtype=torch.float32)\n",
    "    \n",
    "    if epoch == num_epochs-1: rank_confusion = {c: [] for c in train_classes}\n",
    "\n",
    "    for k, i in enumerate(train_idxs):\n",
    "        \n",
    "        model.zero_grad(set_to_none=False)\n",
    "        \n",
    "        if i != -1:\n",
    "            sentence = reviews[i][2:-1].split()\n",
    "            sentence_in = prepare_sequence(sentence, words_to_idxs)\n",
    "            label = list(0 for j in range(len(train_classes)))\n",
    "            for j, key in enumerate(train_dist.keys()):\n",
    "                if int(reviews[i][:2]) == key: label[j] += 1\n",
    "            label = torch.tensor(label, dtype=torch.long)\n",
    "            rank_targets.append(label)\n",
    "\n",
    "            scores = model(sentence_in)\n",
    "            loss = loss_function(scores, torch.tensor([label.argmax(dim=-1)]))\n",
    "            loss.backward()\n",
    "            rank_losses.append(float(loss))\n",
    "            pred = list(0 for j in range(len(train_classes)))\n",
    "            pred[scores.argmax().item()] += 1\n",
    "            pred = torch.tensor(pred, dtype=torch.long)\n",
    "            rank_preds.append(pred)\n",
    "\n",
    "            if epoch == num_epochs-1: rank_confusion[int(reviews[i][:2])].append(scores.argmax().item())\n",
    "\n",
    "        else: loss = torch.tensor([-100.], dtype=torch.float32)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    avg_loss = mean(rank_losses)\n",
    "    training['loss'].append(avg_loss)\n",
    "\n",
    "    preds = torch.cat(rank_preds)\n",
    "    targets = torch.cat(rank_targets)\n",
    "    corrects = (preds == targets)\n",
    "    accuracy = corrects.sum().float() / float(targets.size(0))\n",
    "    training['acc'].append(accuracy)\n",
    "\n",
    "    if epoch%10==0: print('Loss: {}\\tAccuracy: {}'.format(around(avg_loss,4), around(accuracy,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c87662-8368-44de-a69e-f642949d77f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(3.375*3/2, 3.375*4/3), dpi=200)\n",
    "for ax in axs.ravel():\n",
    "    ax.tick_params(labelsize='xx-small')\n",
    "axs[0].set_ylabel('Loss', fontsize='x-small')\n",
    "axs[1].set_ylabel('Accuracy', fontsize='x-small')\n",
    "axs[1].set_xlabel('Epoch', fontsize='x-small')\n",
    "axs[0].plot(training['loss'], lw=1, color=colors[1], label='LSTM');\n",
    "axs[1].plot(training['acc'], lw=1, color=colors[1], label='LSTM');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b791420-451d-4cfc-b67f-2448f7fed64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array, arange\n",
    "\n",
    "print(rank_confusion)\n",
    "confusion = []\n",
    "for i, c in enumerate(rank_confusion.keys()):\n",
    "    temp = list(0 for c in train_classes)\n",
    "    for pc in rank_confusion[c]: temp[pc] += 1/train_dist[c]\n",
    "    confusion.append(temp)\n",
    "confusion = array(confusion)\n",
    "\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784594af-9248-4c39-84ec-98fe4b1a52dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aux import annotate_heatmap\n",
    "\n",
    "labels = list(c for c in train_dist.keys())\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(3.375, 3.375), dpi=150)\n",
    "ax.tick_params(labelsize='small')\n",
    "ax.set_yticks(arange(len(labels)), labels)\n",
    "ax.set_xticks(arange(len(labels)), labels)\n",
    "im = ax.matshow(100*confusion, vmin=0, vmax=100, cmap='gist_heat')\n",
    "texts = annotate_heatmap(im, valfmt='{x:.2f}%', fontsize='small')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b30070-fcd6-4db3-a6cc-9927ef07b8a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnlp-tut",
   "language": "python",
   "name": "qnlp-tut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
